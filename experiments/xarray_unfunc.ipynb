{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import time as t\n",
    "from multiprocess import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['reg_1','reg_2']\n",
    "\n",
    "x_locations = np.arange(3)\n",
    "y_locations = np.arange(3)\n",
    "\n",
    "time = np.arange(3)\n",
    "\n",
    "## time series data\n",
    "ts_var = np.array([ [[[1, 1, 1] for i in range(3)] for i in range(3)],\n",
    "                            \n",
    "                    [[[1, 1, 1] for i in range(3)] for i in range(3)]\n",
    "                   \n",
    "                  ])\n",
    "\n",
    "ts_var_da = xr.DataArray(ts_var, \n",
    "                        coords=[regions, y_locations, x_locations, time], \n",
    "                        dims=['regions', 'y', 'x','time'])\n",
    "\n",
    "## values data\n",
    "values_var = np.array([  [[1, 1, 1] for i in range(3)],\n",
    "\n",
    "                         [[1, 1, 1] for i in range(3)]\n",
    "                ])\n",
    "values_var_da = xr.DataArray(values_var, \n",
    "                            coords=[regions, y_locations, x_locations], \n",
    "                            dims=['regions', 'y', 'x'])\n",
    "\n",
    "ds = xr.Dataset({'ts_var': ts_var_da,\n",
    "                'values_var': values_var_da})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_types = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "aggregated_dict = manager.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _aggregate_xr_ds(region, regional_ds):\n",
    "    \n",
    "    #prepare a resultant xr dataset\n",
    "    time_steps = ds['time'].values\n",
    "    types = [f'type_{i}' for i in range(n_types)] \n",
    "\n",
    "    data = np.zeros((len(time_steps), n_types))\n",
    "\n",
    "    res_ts_var_da = xr.DataArray(data, [('time', time_steps),\n",
    "                                        ('types', types)])\n",
    "\n",
    "    data = np.zeros(len(types))\n",
    "\n",
    "    res_values_var_da = xr.DataArray(data, [('types', types)])\n",
    "        \n",
    "    regional_ts_da = regional_ds['ts_var']\n",
    "    regional_value_da = regional_ds['values_var']\n",
    "\n",
    "    #Preprocess - stack and transpose dimensions \n",
    "    regional_ts_da = regional_ts_da.stack(x_y = ['x', 'y']) \n",
    "    regional_ts_da = regional_ts_da.transpose(transpose_coords= True) \n",
    "\n",
    "    regional_value_da = regional_value_da.stack(x_y = ['x', 'y'])\n",
    "    regional_value_da = regional_value_da.transpose(transpose_coords= True)\n",
    "\n",
    "    #STEP 5d. Aggregation\n",
    "    ## values \n",
    "    res_values_var_da.loc[types[0]] = regional_value_da[dict(x_y=slice(None, 3))].sum()\n",
    "    res_values_var_da.loc[types[1]] = regional_value_da[dict(x_y=slice(3, 9))].sum()\n",
    "    ## ts \n",
    "    res_ts_var_da.loc[:, types[0]] = regional_ts_da[dict(x_y=slice(None, 3))].sum()\n",
    "    res_ts_var_da.loc[:, types[1]] = regional_ts_da[dict(x_y=slice(3, 9))].sum()\n",
    "\n",
    "    #Create resulting dataset \n",
    "    res_ds = xr.Dataset({\"values\": res_values_var_da,\n",
    "                         \"ts\": res_ts_var_da}) \n",
    "    \n",
    "    aggregated_dict.update({region : res_ds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_dict = dict(ds.groupby('regions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "job = [Process(target=_aggregate_xr_ds, args=(key, value)) for key, value in da_dict.items()]\n",
    "_ = [p.start() for p in job]\n",
    "_ = [p.join() for p in job]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(aggregated_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
